<!DOCTYPE html>
<html lang="en">

<head>
<title>CADET</title>
<link rel="icon" href="figures/CADET.png">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
</head>

<body>
<link rel="stylesheet" href="styles.css">

<a href="https://github.com/tomasplsek/CADET">
    <img src="figures/github.png" style="position: relative; width: 100px; left: 0%; top: 17px; float: right; margin-right: 0px;">
</a>

<header>
    <em>Cavity Detection Tool</em>  (CADET)
</header>

<img src="figures/CADET.png" style="float: right; width: 290px; padding-right: 120px; position: fixed; left: 78%; top: 21%;">

<div class="sidenav">
<a id="menu" href="index.html">Overview</a>
<a style="color: rgb(20, 97, 179);font-weight: bold;" id="menu" href="training.html">Training</a>
<a id="menu" href="usage.html">Usage</a>
<a id="menu" href="results.html">Results</a>
<!-- <a id="menu" href="CADET.html">CADET</a> -->
</div>

<main>

<section>

<h1>Training of the CADET pipeline</h1>

<p>
The convolutional neural network was trained on artificial images of simulated galaxies which were 
produced by generating symmetric 3D beta models 
(<a target="_blank" href="https://ui.adsabs.harvard.edu/abs/1978A%26A....70..677C/abstract">Cavaliere et al. 1978</a>) 
into which we randomly inserted ellipsoidal cavities. The parameter ranges and 
distributions used for generating models of galaxies and X-ray cavities were 
estimated from the measurements of nearby galaxies (for more info see the 
<a target="_blank" href="">Plšek et al. 2023</a>). 
Besides X-ray cavities, we added other features such as bright rims around X-ray cavities 
and antisymmetric spiral perturbations resembling gas sloshing (see image below) to imitate the gas distribution of real galaxies. 
The produced models were summed into 2D images a noised using Poisson statistics to resemble real <em>Chandra</em>-like images. 
The corresponding labels were produced similarly by summing ellipsoidal cavity masks 
into 2D images and binning them to contain either ones (inside the cavity) and zeros (outside of it).

<br class="longbr">

The convolutional neural network (CNN) was implemented using a high-level Python <em>Keras</em> 
library with <em>Tensorflow</em> back-end. The CNN was written using a functional <em>Keras</em> 
API which enables saving and loading the model into the Hierarchical Data Format (HDF5) without 
the need to re-defining the model when loading. For the clustering task, we used the DBSCAN 
implementation in the <em>Scikit-Learn</em> library. For monitoring learning curves, comparing 
final test statistics and selecting optimal hyper-parameters, we used the <em>Tensorboard</em> dash-boarding tool.

Elliptical β-models and ellipsoidal cavities were generated with the use of the 
<a src="https://github.com/google/jax"><em>JAX</em></a> library (version 0.2.26).
The training data was created `on the fly` during the training of the network - a mini-batch of images 
was generated by the data generator function before each gradient update. Thanks to the Graphical 
Processing Unit (GPU) support of the \textit{JAX} library, training images were generated in a 
vectorized way using the same GPU as was used for training of the network. This dramatically improved 
the data generation time compared to generating the data using a CPU and also enabled additional 
tweaking of the parameters of training images between individual training runs.

</p>

<br>

<img src="figures/nocav.png" title="Artificial data" style="width: 100%;">
<img src="figures/cavities.png" title="Artificial data" style="width: 100%;">
<img src="figures/rim1.png" title="Artificial data" style="width: 100%;">
<img src="figures/rim2.png" title="Artificial data" style="width: 100%;">
<img src="figures/sloshing.png" title="Artificial data" style="width: 100%;">

<br class="longbr">

</section>

</main>

<footer>
&#169; Tomáš Plšek <span style="font-weight: bolder;">&middot;</span> červenec 2021
</footer>    

</body>

</html>