<!DOCTYPE html>
<html lang="cs">
<head>
<link rel="icon" href="figures/logo.png">
<!-- <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> -->
<title>CADET</title>
</head>


<body>
<link rel="stylesheet" href="styles.css">

<header><em>Cavity Detection Tool</em> (CADET)<img src="figures/CADET.png" style="float: right; width: 200px;"></header>

<main>

<section>

<h1>Overview</h1>

<p>
CADET is a machine learning pipeline trained for identifying surface 
brightness depressions (so-called <em>X-ray cavities</em>) on noisy <em>Chandra</em> 
images of elliptical galaxies. The pipeline consists of a convolutional 
neural network trained for producing pixel-wise cavity predictions, 
which are afterwards decomposed into individual cavities using a DBSCAN 
clustering algorithm.
</p>

<p>
The pipeline was developed as a part of my 
<a target="_blank" href="https://is.muni.cz/th/x68od/?lang=en">Diploma thesis</a> 
(<a href="/pdfs/diploma_thesis.pdf">pdf</a>) to improve the automation 
and accuracy of the detection and size-estimation of <em>X-ray cavities</em>. 
The architecture of the convolutional network consists of 5 convolutional 
blocks, each resembling an inception layer, and it's development was 
inspired by <a target="_blank" href="https://ui.adsabs.harvard.edu/abs/2017arXiv171200523F/abstract">Fort et al. 2017</a> 
and <a target="_blank" href="https://is.muni.cz/th/rnxoz/?lang=en;fakulta=1411">Seck√° 2019</a>. 
The utilized clustering algorithm is the <em>Sklearn</em> implementation of the 
Density-Based Spatial Clustering of Applications with Noise (DBSCAN, 
<a target="_blank" href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.121.9220">Ester et al. 1996</a>).
</p>

<br>

<img src="figures/architecture.png" title="Architecture of the CADET pipeline" style="width: 100%;">

<br>

<p>
The convolutional neural network was trained on artificial images which were 
produced from generated 3D beta models 
(<a target="_blank" href="https://ui.adsabs.harvard.edu/abs/1978A%26A....70..677C/abstract">Cavaliere et al. 1978</a>) 
into which we randomly inserted ellipsoidal cavities. The parameter ranges and 
distributions used for generating models of galaxies and X-ray cavities were 
estimated from the measurements of nearby galaxies (for more info see the 
<a target="_blank" href="https://github.com/tomasplsek/CADET/blob/main/pdfs/diploma_thesis.pdf">Diploma thesis</a>). 
Besides the cavities, we added also other typical features such as central point sources, 
bright rims around cavities and also antisymmetric spiral perturbations resembling gas 
sloshing (see image below) to imitate the gas distribution of real galaxies. The produced models were summed 
into 2D images a noised using Poisson statistics to resemble real <em>Chandra</em>-like images. 
The corresponding labels were produced similarly by summing the ellipsoidal cavity masks 
into 2D images and binning them to contain either ones (inside the cavity) and zeros (outside of it).
</p>

<br>

<img src="figures/artificial.png" title="Artificial data" style="width: 100%;">

<br>

<p>
We have trained two separate networks using different sets of artificial images:
one purely with galaxies containing cavities (<b><em>CADET_size</em></b>) and the second with
50 percent of galaxies lacking any cavities (<b><em>CADET_search</em></b>). The first network
was further optimized for the proper estimation of cavity sizes, while the second network
was tuned to suppress false positive cavity detections. For both networks, 300 000
artificial images and corresponding labels were generated for training, 10 000 for
validation and 10 000 for testing of the network. Their parameters were drawn from
identical ranges and distributions. Using 64 cores on Intel Xeon Silver 4216 CPU, 
the data generation process took nearly 18 hours. The dataset was generated by the
<code>generator.py</code> script, which loads the distributions of the parameters stored in 
the <code>CADET_size_params.csv</code> and <code>CADET_search_params.csv</code> files and uses the beta
model class in the <code>beta_model.py</code> module. Functions utilized for generation of 
ellipsoids and 3D array rotations contained in the <code>beta_model.py</code> module are inspired 
by the <a target="_blank" href="https://pypi.org/project/pyellipsoid/">pyellipsoid</a> package. 
The networks were trained using the <em>ADaptive Moment Estimation</em> (ADAM) optimizer 
and the minimized loss function was the pixel-wise <b><em>binary cross-entropy</em></b>. 
The pipelines were trained for 5 epochs with 8 images per batch while using all of 
the training images in each epoch. The training was performed using an NVIDIA GPU 
type GeForce RTX 2080 SUPER (8 GiB) and lasted approximately 6 hours for both pipelines.
</p>

<br>

<hr>

<br>

<h1>Requirements</h1>

libraries required for using the CADET pipeline:<br>
<code>astropy</code><br>
<code>keras</code><br>
<code>matplotlib</code><br>
<code>numpy</code><br>
<code>scipy</code><br>
<code>sklearn</code><br>
<code>tensorflow</code><br>
<code>plotly</code> (optionally)<br><br>

additional libraries for data generation:<br>
<code>concurrent</code>

<hr>

<h1>Usage</h1>

<p>The CADET pipeline inputs either raw <em>Chandra</em> images with units of counts 
(numbers of captured photons) or normalized processed background-subtracted 
and/or exposure-corrected images. When using flux images for instance, try 
normalizing them by the lowest pixel value so all pixel values are higher 
than or equal to unity. The input image is afterwards automatically scaled 
by a logarithm and normalized by the highest pixel value. Currently only 
128x128 images are supported, however, an improvement that would enable 
arbitrarily sized images is under development (so-far the images were cropped 
and re-binned via ciao_contrib (CIAO 4.13), however, an Astropy version is being developed).
Both the <b><em>CADET_search</em></b> and <b><em>CADET_size</em></b> pipelines 
are composed as self-standing scripts. Discrimination threshold for the <b><em>CADET_search</em></b> 
pipeline was set to 0.9 to suppress false positive detections, while the threshold of the 
<b><em>CADET_size</em></b> pipeline was set to 0.55 so the predicted volumes are not underestimated 
nor overestimated (for more info see the <a target="_blank" href="https://github.com/tomasplsek/CADET/blob/main/pdfs/diploma_thesis.pdf">Diploma thesis</a>). 
However, the thresholds of both pipelines are changeable and can be set to an arbitrary value between 0 and 1.
The scripts can be run by simply calling (possibly with a threshold parameter - float from 0 to 1):

<br><br>

<code>$ python3 CADET_size.py foldername [threshold]</code>

<br><br>

and

<br><br>

<code>$ python3 CADET_search.py foldername [threshold]</code>

<br><br>

which uses all <code>.fits</code> files in the corresponding folder 
<code>foldername</code>) and saves their raw cavity predictions into the
<code> .fits</code> files while also properly preserving the WCS coordinates. 
On the output there is also a <code>.png</code> file showing decomposed 
cavities and a <code>.txt</code> file containing calculated areas and cavity volumes.
The volumes of X-ray cavities are calculated under the assumption of a 
symmetry along the direction from the galactic centre into the centre of 
the cavity (<em>center of mass</em>). The cavity depth in each point along 
that direction is assumed to be equal to its width. Thereby produced 3D 
cavity models can be alternatively viewed or stored in the <code>.npy</code> 
format for further use (e.g. cavity energy calculation).</p>

<br>

<h2>Convolutional part</h2>

<p>
The convolutional part can be used separately to produce raw pixel-wise predictions. 
Since the architecture of the convolutional network was implemented using the 
functional *Keras* API, the architectures together with trained weights could 
have been stored in the HDF5 format (<em>CADET_size.h5</em>, <em>CADET_search.h5</em>). 
The trained models can be simply loaded using the <code>load_model</code> <em>Keras</em> function.

<br><br>
<code>
from keras.models import load_model<br>
from keras.layers import LeakyReLU<br>
<br>
model = load_model("CADET_size.h5", custom_objects = {"LeakyReLU": LeakyReLU})<br>
<br>
y_pred = model.predict(X)
</code>
<br><br>

The network inputs 128x128 images. However, to maintain the compatibility with <em>Keras</em>, 
the input needs to be reshaped as <code>X.reshape(1, 128, 128, 1)</code> for single image or as 
<code>X.reshape(len(X), 128, 128, 1)</code> for multiple images.
</p>

<br>

<hr>

<h1>Example</h1>

<p>
Here we present an example of the pipeline being used on real <em>Chandra</em> images of giant elliptical galaxies.
</p>

<!-- [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tomasplsek/CADET/blob/main/CADET_example_colab.ipynb) [![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/tomasplsek/CADET/HEAD?filepath=CADET_example_binder.ipynb) -->

<div class="row">
    <div class="column">
        <a target="_blank" href="https://colab.research.google.com/github/tomasplsek/CADET/blob/main/CADET_example_colab.ipynb">
        <img src="https://colab.research.google.com/assets/colab-badge.svg" title="Open in Google Colab" style="width: 110px; padding-right: 5px;"></a> 
    </div>
    <div class="column">
        <a target="_blank" href="https://mybinder.org/v2/gh/tomasplsek/CADET/HEAD?filepath=CADET_example_binder.ipynb">
        <img src="https://mybinder.org/badge_logo.svg" title="Open in Binder" style="width: 102px;"></a>    
    </div>
</div>

<br>
<img src="figures/NGC4696_CADET_size.png" title="Example of CADET utilization for NGC4696" style="width: 100%;">
<img src="figures/NGC4778_CADET_size.png" title="Example of CADET utilization for NGC4778" style="width: 100%;">
<img src="figures/NGC5813_CADET_size.png" title="Example of CADET utilization for NGC5813" style="width: 100%;">

<hr>

<h1>Todo</h1>

<p>
The following improvements for the data generation and training processes 
are currently planned:

<ul style="list-style-type:circle;">
<li>speed up the data generation using <em>Tensorflow</em> and GPU</li>
<li>enable inputting arbitrarily sized images</li>
<li>add other features (cold fronts, point sources)</li>
<li>improve existing features (bright rims, gas sloshing)</li>
<li>examine various other CNN architectures</li>
<li>restrict the cavity predictions using output regularization</li>
</ul> 
</p>

</section>

</main>

</body>